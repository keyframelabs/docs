---
title: "Overview"
description: "Choose the right integration approach for your use case"
---

Keyframe personas integrate with both agent frameworks (e.g., ElevenLabs, Cartesia) and live model APIs (e.g., Gemini Live, OpenAI Realtime). While each integration has minor setup differences, the overall flow is largely the same:

```
+---------------------+                                     +--------------------------+
|                     | ---------- User input ------------> |                          |
|                     |                                     |    Your existing agent   |
|                     | <--- Raw agent / model audio ------ |         or model         |
|                     |       (will now be "relayed")       |                          |
|                     |                                     +--------------------------+
|   Your client app   |
|                     |                                     +--------------------------+
|                     | ------ Relayed agent audio -------> |                          |
|                     |                                     |         Keyframe         |
|                     | <------ Rendered persona ---------- |         platform         |
|                     |    (w/ synced audio and video)      |                          |
+---------------------+                                     +--------------------------+
```

In essence, your client app continues to interface with your existing agent framework or live model API, and Keyframe's no-code or low-code components take care of relaying "raw" agent / model audio to the Keyframe platform and rendering a persona synced with said audio.